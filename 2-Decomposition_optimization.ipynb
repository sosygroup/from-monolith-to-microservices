{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce5fa3-e2cb-4565-ba94-8fa943d68162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import networkx as nx\n",
    "import pygraphviz as pygv\n",
    "import gurobi as gb\n",
    "import json\n",
    "from community import community_louvain\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def DrawSol (G, x, filename):\n",
    "    global n_micros\n",
    "\n",
    "    DrawG = pygv.AGraph(directed=True, strict='true', splines='true')\n",
    "\n",
    "    colors = ['green', 'blue', 'red', 'orange', 'yellow', 'purple', 'black', 'gray', 'cyan', 'brown', 'hotpink', 'navy', 'darkgreen', 'chocolate', 'deeppink', 'firebrick', 'gold', 'orchid', 'gold4']\n",
    "    \n",
    "    for i in G.nodes():\n",
    "        if G.nodes[i]['type'] == 'Entity':\n",
    "            shape='hexagon'\n",
    "        else:\n",
    "            shape='circle'\n",
    "\n",
    "        for k in range(n_micros):\n",
    "            if x[i,k].x == 1:\n",
    "                # Get cluster number k\n",
    "                if k<len(colors):\n",
    "                    color=colors[k]\n",
    "                else:\n",
    "                    color = 'black'\n",
    "        DrawG.add_node (i, color=color, shape=shape, width=0.1, fontsize=9, label=G.nodes[i]['name'])\n",
    "\n",
    "    for i in G.edges():\n",
    "        edge_color = 'black' if G[i[0]][i[1]]['rel_type'] in ['Calls','Persists', 'References'] else 'gray'\n",
    "        DrawG.add_edge(i[0], i[1], color=edge_color, label=G[i[0]][i[1]]['rel_type'], fontsize='8')\n",
    "        \n",
    "    DrawG.layout(prog='dot')\n",
    "    DrawG.draw(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e92b53-40f6-4740-8a99-c40877eb9681",
   "metadata": {
    "tags": []
   },
   "source": [
    "### _Configuration!_\n",
    "\n",
    "Keep the project list up-to-date and select the project to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654afedb-2f70-4c65-b23e-5e01c98d8d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = 'jpetstore' # <-- Set this variable!\n",
    "\n",
    "with open('projects.json', 'r') as projects:\n",
    "    project_found = False\n",
    "    for data in json.load(projects):\n",
    "        if data['name'] == project:\n",
    "            analysis_results_basedir = data['analysis_results_basedir']\n",
    "            project_found = True\n",
    "    if not project_found:\n",
    "        print('ERROR: project ' + project + ' does not appear in project.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f6589-5ded-4162-85ea-3c37b9026765",
   "metadata": {},
   "source": [
    "### _User input required!_\n",
    "\n",
    "Update, if needed the default weigth of the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53fae46-ba1e-4194-9c74-a6815eff515c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Weighting edges:\n",
    "w = dict()\n",
    "w['Calls']=0.8\n",
    "w['Persists']=1\n",
    "w['Uses']=0.6\n",
    "w['References']=0.2\n",
    "w['Extends']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2f54d-61ce-4b68-a80a-68b94ef0ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output names\n",
    "\n",
    "graph_in = analysis_results_basedir + project + '_graph.gml'\n",
    "communities_out = analysis_results_basedir + project + '_communities.csv'\n",
    "formulation_out = analysis_results_basedir + project + '_communities_improved_optimization.lp'\n",
    "solution_csv_out = analysis_results_basedir + project + '_sol_communities_improved_optimization.csv'\n",
    "graph_image_out = analysis_results_basedir + project + '_sol_communities_improved_optimization.png'\n",
    "analysis_out = analysis_results_basedir + project + '_sol_communities_improved_optimization.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c34a6-0072-4335-aa24-5592aa2b0eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import graph\n",
    "\n",
    "G = nx.read_graphml(graph_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce09914-e79b-4094-8343-eb55557825f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add edge weights\n",
    "\n",
    "for (i, j) in G.edges():\n",
    "    G[i][j]['w'] = w[G[i][j]['rel_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98c18d6-f80e-47f3-91bd-258d444d2d08",
   "metadata": {},
   "source": [
    "## Find communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1205d9e-4492-4c2d-8034-52c4323b3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = nx.Graph(G) # create an undirected graph H from a directed graph G\n",
    "\n",
    "# compute the best partition\n",
    "communities = community_louvain.best_partition(H, weight='w')\n",
    "\n",
    "# write communities on file\n",
    "with open(communities_out, 'w') as csv_file:\n",
    "    csv_file.write('node, cluster/community\\n')\n",
    "    for node in communities:\n",
    "        csv_file.write(f'{node},{communities[node]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6627e68-4939-4275-8ed8-43a323b64d2e",
   "metadata": {},
   "source": [
    "## Find communities for the entity subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f02c9-d605-4213-8225-951cd9beb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = nx.Graph(G) # create an undirected graph H from a directed graph G\n",
    "\n",
    "# Remove non-entity nodes\n",
    "\n",
    "for i in list(K.nodes):\n",
    "    if K.nodes[i]['type']!='Entity':\n",
    "        K.remove_node(i)\n",
    "\n",
    "# Obtain subgraph of entities that have direct relationships with the persistence layer:\n",
    "    \n",
    "        \n",
    "# compute the best partition\n",
    "entity_cluster = community_louvain.best_partition(K, weight='w')\n",
    "\n",
    "# Remove nodes that do not have direct relationships with methods from the cluster dictionary:\n",
    "e_dict = dict()\n",
    "# Check if entity has a relationship with some method of the persistence layer (it will remove entities from the controller model, for instance)\n",
    "for e in entity_cluster:\n",
    "    e_dict[e] = False\n",
    "    for (i,j) in G.edges():\n",
    "        if e==j and G[i][j]['rel_type'] in ['Persists']:\n",
    "            e_dict[e]=True\n",
    "\n",
    "# Remove non-related entities\n",
    "for entity_to_remove in e_dict:\n",
    "    if not e_dict[entity_to_remove]:\n",
    "        # print('INFO: Entity ' + G.nodes[entity_to_remove]['name'] + ' removed from the clusters')\n",
    "        entity_cluster.pop(entity_to_remove)\n",
    "\n",
    "for i in set(entity_cluster.values()):\n",
    "    print(f'Community {i}:')\n",
    "    for entity, cluster in entity_cluster.items():\n",
    "        if cluster == i:\n",
    "            print(f' - {G.nodes()[entity][\"name\"]} (id:{entity})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d385bf2-cf31-45e0-8d84-fd44715a1028",
   "metadata": {},
   "source": [
    "### _User input required!_\n",
    "\n",
    "Refine, if needed, entity clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021636e9-07ea-45c6-9eab-e34e93503e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entity from its cluster\n",
    "entity_ids_to_remove = [] # <-- Put Ids as strings (example: ['1', '3']\n",
    "\n",
    "# Place entity into a cluster\n",
    "entities_clusters_to_place = [] # <-- Example: entity X in cluster Y: ('X', 5)\n",
    "\n",
    "\n",
    "for e in entity_ids_to_remove:\n",
    "    entity_cluster.pop(e)\n",
    "    print(f'INFO: Removed entity {G.nodes()[e][\"name\"]} from clusters')\n",
    "\n",
    "for (e, cluster) in entities_clusters_to_place:\n",
    "    entity_cluster[e] = cluster\n",
    "    print(f'INFO: Entity {G.nodes()[e][\"name\"]} put into cluster {cluster}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb8c9a-f2d0-46ad-a857-11e31be27470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some cluster may have disappeared: remaining clusters need to be renumbered\n",
    "cluster_map = dict()\n",
    "counter=0\n",
    "number_mapping = dict() # maps the old cluster number with the new one\n",
    "for entity_key, old_number in entity_cluster.items():\n",
    "    if old_number not in number_mapping:\n",
    "        number_mapping[old_number] = counter\n",
    "        counter+=1\n",
    "    cluster_map[number_mapping[old_number]] = cluster_map.get(number_mapping[old_number], []) + [entity_key]\n",
    "    \n",
    "for cluster in cluster_map:\n",
    "    print('Entities in community ' + str(cluster) + ': ' + str([G.nodes[entity_key]['name'] for entity_key in cluster_map[cluster]]))\n",
    "\n",
    "n_micros = len(cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd909d53-3681-43aa-baa0-5d38556bb40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve conflicts of distribution of entities into communities: if entities of the same community are in different clusters, then remove the community from the dictionary\n",
    "\n",
    "communities_dict = dict() # Map community -> entities into the communities\n",
    "\n",
    "\n",
    "for node in G.nodes():\n",
    "    if G.nodes[node]['type'] == 'Entity':\n",
    "        communities_dict[communities[node]] = communities_dict.get(communities[node], []) + [node]\n",
    "\n",
    "communities_to_relax = []\n",
    "\n",
    "for community in communities_dict:\n",
    "    clusters = []\n",
    "    for cluster, entities in cluster_map.items():\n",
    "        for e in entities:\n",
    "            if e in communities_dict[community]:\n",
    "                clusters.append(cluster)\n",
    "    print(f'Entities in community {community} are in clusters: {clusters}')\n",
    "    if len(clusters) > 0 and not all(clusters[0] == c for c in clusters):\n",
    "        #print(f'Remove community {community}')\n",
    "        communities_to_relax.append(community)\n",
    "\n",
    "nodes_to_remove_from_dict = []\n",
    "for node in communities.keys():\n",
    "    if communities[node] in communities_to_relax:\n",
    "        nodes_to_remove_from_dict.append(node)\n",
    "\n",
    "for node in nodes_to_remove_from_dict:\n",
    "    del communities[node]\n",
    "\n",
    "print(f'Relaxed communities: {communities_to_relax}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6fe2ac-0fb0-456d-8b81-8d93a3439be8",
   "metadata": {},
   "source": [
    "## ILP Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb7240-b83a-4b0b-b380-b95cd1bb2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gb.Model()\n",
    "\n",
    "# Variables\n",
    "x = model.addVars(((i,k) for i in G.nodes() for k in range(n_micros)),\\\n",
    "                  vtype=gb.GRB.BINARY, name='x')\n",
    "\n",
    "z = model.addVars(((i,j,k) for (i,j) in G.edges() for k in range(n_micros)), vtype=gb.GRB.BINARY, name='z')\n",
    "\n",
    "y = model.addVars(((i,j) for (i,j) in G.edges()), vtype=gb.GRB.BINARY, name='y')\n",
    "\n",
    "# Each node has to be in one and only one microservice\n",
    "model.addConstrs((x.sum(i, '*') == 1 for i in G.nodes()), name='(1)microservice-belonging')\n",
    "\n",
    "# A microservice can not be composed of entities only\n",
    "model.addConstrs((gb.quicksum(x[i,k] for i in G.nodes() if G.nodes[i]['type']!='Entity') >= 1 for k in range(n_micros)), name='(2)microservice-composition')\n",
    "\n",
    "# Bonding variables\n",
    "model.addConstrs((z[i,j,k]-x[i,k] <= 0 for (i,j) in G.edges() for k in range(n_micros)), name='(3)bonding-z-to-x')\n",
    "model.addConstrs((z[i,j,k]-x[j,k] <= 0 for (i,j) in G.edges() for k in range(n_micros)), name='(4)bonding-z-to-x')\n",
    "model.addConstrs((x[i,k]+x[j,k]-z[i,j,k] <= 1 for (i,j) in G.edges() for k in range(n_micros)), name='(5)bonding-z-to-x')\n",
    "\n",
    "model.addConstrs((y[i,j]==gb.quicksum(z[i,j,k] for k in range(n_micros)) for (i,j) in G.edges()), name='(6)bonding-y-to-z')\n",
    "\n",
    "\n",
    "########## Added constraints ##########\n",
    "\n",
    "# Force each entity from the kth cluster to be in the kth microservice\n",
    "model.addConstrs((x[i,k]==1 for k in cluster_map for i in cluster_map[k]), name='(7)bonding-x-to-entity-clusters')\n",
    "\n",
    "# Force node of the same community to be in the same (consider a community only if there are not entities from different clusters)\n",
    "communities_constraint = model.addConstrs((y[i,j]==1 for (i,j) in G.edges() if i in communities and j in communities and communities[i]==communities[j]), name='(8)bonding-y-to-communities')\n",
    "\n",
    "\n",
    "########## Objective function ##########\n",
    "\n",
    "coupling = gb.quicksum(G.edges[i,j]['w']*(1-y[i,j]) for (i,j) in G.edges())\n",
    "\n",
    "model.setObjective(coupling, gb.GRB.MINIMIZE)\n",
    "\n",
    "model.write(formulation_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081eb8b2-d436-45fa-886c-7051ff07d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb0cfd-3f6e-4806-908c-628a86f4574f",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5ab5d-204b-48b6-bec9-9e2647d47855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cohesion:\n",
    "inside_w = dict()\n",
    "outside_w = dict()\n",
    "\n",
    "for i,j in G.edges():\n",
    "    for k in range(n_micros):\n",
    "        if z[i,j,k].x == 1: # Edge (i,j) is inside microservice k: sum the weight as inside\n",
    "            inside_w[k] = inside_w.get(k, 0) + G[i][j]['w']\n",
    "        if x[i,k].x == 1: # Edge (i,j) has its origin in k: sum the weigth as outside\n",
    "            outside_w[k] = outside_w.get(k, 0) + G[i][j]['w']\n",
    "\n",
    "cohesion_dict = dict()\n",
    "for k in range(n_micros):\n",
    "    cohesion_dict[k] = inside_w[k] / outside_w[k]\n",
    "\n",
    "cohesion = sum(cohesion_dict.values())/n_micros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4589c-f9db-4123-89b3-9d1266b6297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_methods = False\n",
    "\n",
    "analysis_output = \"\"\n",
    "\n",
    "analysis_output += f'Found {str(n_micros)} microservices\\n'\n",
    "\n",
    "analysis_output += f'Total coupling value: {model.objVal} ({model.objVal/n_micros} avg.)\\n'\n",
    "analysis_output += f'Cohesion value: {cohesion}\\n\\n'\n",
    "\n",
    "for k in range(n_micros):\n",
    "    analysis_output += f'Entities in Microservice {str(k)}:\\n'\n",
    "    for i in G.nodes():\n",
    "        if G.nodes[i]['type'] == 'Entity' and x[i,k].x == 1:\n",
    "            analysis_output += f'- {G.nodes[i][\"name\"]}\\n'\n",
    "\n",
    "if show_methods:\n",
    "    for k in range(n_micros):\n",
    "        analysis_output += f'\\n\\nMethods in Microservice {str(k)}:\\n'\n",
    "        for i in G.nodes():\n",
    "            if G.nodes[i]['type'] == 'Method' and x[i,k].x == 1:\n",
    "                analysis_output += f'- {G.nodes[i][\"name\"]} ({G.nodes[i][\"class_name\"]})\\n'\n",
    "\n",
    "mcalls = 0\n",
    "references = 0\n",
    "uses = 0\n",
    "persists = 0\n",
    "\n",
    "for i,j in G.edges():\n",
    "    if y[i,j].x == 0:\n",
    "        if G[i][j]['rel_type'] == 'Calls':\n",
    "            mcalls += 1 \n",
    "        elif G[i][j]['rel_type'] == 'References':\n",
    "            references += 1\n",
    "        elif G[i][j]['rel_type'] == 'Uses':\n",
    "            uses += 1\n",
    "        elif G[i][j]['rel_type'] == 'Persists':\n",
    "            persists += 1\n",
    "\n",
    "analysis_output += f'\\n\\n\\n# of method calls crossing microservices: {mcalls}'\n",
    "analysis_output += f'\\n# of entity references crossing microservices: {references}'\n",
    "analysis_output += f'\\n# of entity usages crossing microservices: {uses}'\n",
    "analysis_output += f'\\n# of methods persisting entities of other microservices: {persists}'\n",
    "\n",
    "print(analysis_output)\n",
    "\n",
    "with open(analysis_out, 'w') as analysis_file:\n",
    "    analysis_file.write(analysis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519b123-a48c-4070-ab5f-b17393c76ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(solution_csv_out, 'w') as results_csv:\n",
    "    results_csv.write('node_key,microservice\\n')\n",
    "    counter = 0\n",
    "    for i in G.nodes():\n",
    "        for k in range(n_micros):\n",
    "            if x[i,k].x == 1:\n",
    "                results_csv.write(f'{i},{k}\\n')\n",
    "                counter+=1\n",
    "    \n",
    "    if counter!=len(G.nodes()):\n",
    "        print('Error! There are nodes not assigned into microservices?!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8cfeef-174f-4742-ac5f-4862676bad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawSol(G, x, graph_image_out)\n",
    "\n",
    "display(Image(filename = graph_image_out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('micros')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "84d57bcf988df7741739090f92038d55c89d5ee4bebfcc0bea6a6c98a16573ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
